{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning \n",
    "\n",
    "In this notebook, I implement the ensemble Learning  based on the * **Shill Bidding Dataset** *, including Bagging、Random Forests、Adaboost and Gradient Boosting.\n",
    "\n",
    "I implement the algorithm with the notes defined in * **Lecture 9.1~9.2 Ensemble Methods.** *.\n",
    "\n",
    "## Algorithm Inplement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,mean_squared_error,r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier,GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record_ID</th>\n",
       "      <th>Auction_ID</th>\n",
       "      <th>Bidder_ID</th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>_***i</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>732</td>\n",
       "      <td>g***r</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>732</td>\n",
       "      <td>t***p</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>732</td>\n",
       "      <td>7***n</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>z***z</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record_ID  Auction_ID Bidder_ID  Bidder_Tendency  Bidding_Ratio  \\\n",
       "0          1         732     _***i         0.200000       0.400000   \n",
       "1          2         732     g***r         0.024390       0.200000   \n",
       "2          3         732     t***p         0.142857       0.200000   \n",
       "3          4         732     7***n         0.100000       0.200000   \n",
       "4          5         900     z***z         0.051282       0.222222   \n",
       "\n",
       "   Successive_Outbidding  Last_Bidding  Auction_Bids  Starting_Price_Average  \\\n",
       "0                    0.0      0.000028           0.0                0.993593   \n",
       "1                    0.0      0.013123           0.0                0.993593   \n",
       "2                    0.0      0.003042           0.0                0.993593   \n",
       "3                    0.0      0.097477           0.0                0.993593   \n",
       "4                    0.0      0.001318           0.0                0.000000   \n",
       "\n",
       "   Early_Bidding  Winning_Ratio  Auction_Duration  Class  \n",
       "0       0.000028       0.666667                 5      0  \n",
       "1       0.013123       0.944444                 5      0  \n",
       "2       0.003042       1.000000                 5      0  \n",
       "3       0.097477       1.000000                 5      0  \n",
       "4       0.001242       0.500000                 7      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"../3. Data/Shill_Bidding_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Record_ID','Auction_ID','Bidder_ID','Class'],axis=1)\n",
    "y = df.Class\n",
    "\n",
    "# Create a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Scikit-Learn, we import ```DecisionTreeClassifier``` and ```BaggingClassifier```. We instantiate an instance of ```BaggingClassifier``` which trains an ensemble of 500 ```DecisionTreeClassifier``` with max_depth = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99      1699\n",
      "          1       0.86      0.98      0.92       198\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1897\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=3, random_state=23),\n",
    "                            n_estimators = 500,\n",
    "                            bootstrap = True,\n",
    "                            n_jobs = -1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_y_pred = bag_clf.predict(X_test)\n",
    "print(f\"Bagging Classification Report\")\n",
    "print(classification_report(y_test, bag_y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99      1699\n",
      "          1       0.85      0.98      0.91       198\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1897\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(max_depth = 3, \n",
    "                                    n_estimators = 500,\n",
    "                                    bootstrap = True,\n",
    "                                    n_jobs = -1)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "forest_y_pred = forest_clf.predict(X_test)\n",
    "print(f\"Forest Classification Report\")\n",
    "print(classification_report(y_test, forest_y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for random forests is same as bagging. However, the precision of positive sample performed by random forest is better than bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Feature Importance \n",
    "Another great quality of Random Forests is that they make it easy to measure the relative importance of each feature. Scikit-Learn measures a feature’s importance bylooking at how much the tree nodes that use that feature reduce impurity on average (across all trees in the forest). More precisely, it is a weighted average, where each\n",
    "node’s weight is equal to the number of training samples that are associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bidder_Tendency 0.03518456451080783\n",
      "Bidding_Ratio 0.2139412826006667\n",
      "Successive_Outbidding 0.598802971783876\n",
      "Last_Bidding 0.006190933950224021\n",
      "Auction_Bids 0.036076670697468054\n",
      "Starting_Price_Average 0.008009247482470842\n",
      "Early_Bidding 0.006784865384835935\n",
      "Winning_Ratio 0.09126221818740424\n",
      "Auction_Duration 0.00374724540224616\n"
     ]
    }
   ],
   "source": [
    "names = X_train.columns.tolist()\n",
    "for name, score in zip(names, forest_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the feature importance for 'Successive_Outbidding','Bidding_Ratio', 'Winning_Ratio' is higher than other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1699\n",
      "          1       0.99      0.97      0.98       198\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1897\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3, random_state=23), \n",
    "                             n_estimators = 10,\n",
    "                             algorithm = \"SAMME.R\",\n",
    "                             learning_rate = 0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "ada_y_pred = ada_clf.predict(X_test)\n",
    "print(f\"AdaBoost Classification Report\")\n",
    "print(classification_report(y_test, ada_y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performance for AdaBoost is better than Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for gb_reg is: 0.005057274697830985\n",
      "The R^2 for gb_reg is: 0.946\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor(max_depth = 3, n_estimators = 150, random_state=23)\n",
    "gb_reg.fit(X_train, y_train)\n",
    "gb_y_pred = gb_reg.predict(X_test)\n",
    "\n",
    "print(f\"MSE for gb_reg is: {mean_squared_error(y_test, gb_y_pred)}\")\n",
    "print(f\"The R^2 for gb_reg is: {round(r2_score(y_test, gb_y_pred), 3)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e3de3013aa64c987b0d0ea220a933b22b0d06ac8866ebafdf417a10062e273"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
