# Ensemble Learning
This folder contains the implementation of the Ensemble Learning Model.

## Description
In this notebook, I implemented the ensemble Learning based on the Shill Bidding Dataset, including Bagging, Random Forests, Adaboost and Gradient Boosting. Each model was trained on the train data and their performance was measure on the test data. In the end, the AdaBoost performed better than Random Forests and Bagging. Gradient Boosting also performed well with MSE 0.005 and R^2 0.946.

## Reference
Most of the contents in Linear_Regression.ipynb file are based on Dr. Davila's Lecture Notes and our text book 'Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow'.